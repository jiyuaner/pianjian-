{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11081302,"sourceType":"datasetVersion","datasetId":6888932},{"sourceId":11458156,"sourceType":"datasetVersion","datasetId":7179473}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:01:05.358683Z","iopub.execute_input":"2025-05-19T04:01:05.358949Z","iopub.status.idle":"2025-05-19T04:04:16.094577Z","shell.execute_reply.started":"2025-05-19T04:01:05.358931Z","shell.execute_reply":"2025-05-19T04:04:16.093845Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.5.6-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.5.7 (from unsloth)\n  Downloading unsloth_zoo-2025.5.7-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.20-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers!=4.47.0,==4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.51.3)\nRequirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.5.2)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.31.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.2)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (3.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.5.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.5.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.7->unsloth) (11.1.0)\nCollecting msgspec (from unsloth_zoo>=2025.5.7->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (3.11.18)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2025.4.26)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.20.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.5.6-py3-none-any.whl (265 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.6/265.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.5.7-py3-none-any.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.20-py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 fsspec-2025.3.0 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 shtab-1.7.2 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0 trl-0.15.2 tyro-0.9.20 unsloth-2025.5.6 unsloth_zoo-2025.5.7 xformers-0.0.30\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\n# 检查数据集是否存在\ndataset_path = \"/kaggle/input/pianjian\"\nif os.path.exists(dataset_path):\n    print(\"✅ 数据集目录存在\")\n    print(\"目录内容:\", os.listdir(dataset_path))\nelse:\n    print(f\"❌ 路径错误: {dataset_path} 不存在\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:04:33.812415Z","iopub.execute_input":"2025-05-19T04:04:33.812724Z","iopub.status.idle":"2025-05-19T04:04:33.820767Z","shell.execute_reply.started":"2025-05-19T04:04:33.812696Z","shell.execute_reply":"2025-05-19T04:04:33.819946Z"}},"outputs":[{"name":"stdout","text":"✅ 数据集目录存在\n目录内容: ['ceshi biased.json', 'yanzheng biased.json', 'non-biased.json', 'biased.json', 'yanzhneg non-biased.json', 'ceshi non-biased.json']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 示例脚本，演示如何使用来自Hugging Face的思维链(COT)数据集\n\nimport torch\nfrom unsloth import FastLanguageModel\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom tqdm import tqdm\nimport re\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:04:37.396624Z","iopub.execute_input":"2025-05-19T04:04:37.396859Z","iopub.status.idle":"2025-05-19T04:05:10.150518Z","shell.execute_reply.started":"2025-05-19T04:04:37.396844Z","shell.execute_reply":"2025-05-19T04:05:10.149909Z"}},"outputs":[{"name":"stdout","text":"🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-05-19 04:04:48.152287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747627488.379036      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747627488.437436      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"🦥 Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 直接从Hugging Face加载COT数据集\nprint(\"正在从Hugging Face加载COT数据集...\")\n# enhanced_dataset = load_dataset(dataset_name, split=\"train\")\n\nHF_TOKEN = \"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\"  \n\n# 明确指定数据路径和令牌\nenhanced_dataset = load_dataset(\n    \"pianjian/pianjian-with-cot\",\n    data_dir=\"data\",  \n    split=\"train\",\n    token=HF_TOKEN  # 关键：添加私有数据集访问权限\n)\nprint(f\"已加载{len(enhanced_dataset)}个带有思维链推理的示例\")\n# 初始化模型\nmax_seq_length = 2048\ndtype = torch.float16  # 用于4位量化\nload_in_4bit = True\n\nprint(\"正在加载模型...\")\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/Qwen2.5-7B-Instruct\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:05:20.831886Z","iopub.execute_input":"2025-05-19T04:05:20.832949Z","iopub.status.idle":"2025-05-19T04:06:13.552328Z","shell.execute_reply.started":"2025-05-19T04:05:20.832925Z","shell.execute_reply":"2025-05-19T04:06:13.551741Z"}},"outputs":[{"name":"stdout","text":"正在从Hugging Face加载COT数据集...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/448 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545b34c9d9684f9bb8b742f6ae372cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/550k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716b61cfbc4f4288915e40bd0c1dbce6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"057729301de54c6d8dc3fc2aa3f32b4b"}},"metadata":{}},{"name":"stdout","text":"已加载1000个带有思维链推理的示例\n正在加载模型...\n==((====))==  Unsloth 2025.5.6: Fast Qwen2 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 6.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/112k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98de83aeb3214b78806a0d595a441f1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28152c170ff4be188a51ee175a432ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6f36eb473749ec8986198d31f81553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"894a67ccf81e4df4974b0ad68a53b1d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"936d38f31570432cb7e635e834a6a692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"125ebe9de90748dfa2a31350465c2b33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0401336e55d242c69e82075a843478b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dc7da486f064c679990c69dc0937612"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51fd4343a75447a3bf7aee00defb92d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0360fa2b7fbf42128ddbe7e7f976036a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad9c1253042410987575bdd3e3d046d"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# 修改后的训练提示模板（增强逻辑一致性）\ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with\nan input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert in social bias analysis with advanced knowledge in identifying \nand interpreting gender-related stereotypes. Please complete the following steps:\n1. Analyze the text for potential gender bias\n2. Generate a chain-of-thought explanation\n3. Provide your final bias classification (0=biased, 1=neutral)\n\n### Text:\n{}\n\n### Response (Chain of Thought):\n{}\n\n### Final Answer:\n{}\"\"\"  # 修改为二元分类任务\n\n# 定义标签转换函数（根据您的业务需求调整）\ndef convert_label(bias_labels):\n    \"\"\"将三维偏见标签转换为二元分类标签\"\"\"\n    # 示例逻辑：任一维度存在偏见则标记为0，中性为1\n    return 0 if sum(bias_labels) > 0 else 1\n\n# 修改后的格式化函数\ndef formatting_prompts_func(examples):\n    inputs = examples[\"original_text\"]  # 映射原始字段\n    cots = examples[\"Bias_Analysis_CoT\"]\n    labels = [convert_label(l) for l in examples[\"bias_labels\"]]  # 标签转换\n    \n    texts = []\n    for input_text, cot, label in zip(inputs, cots, labels):\n        formatted_text = train_prompt_style.format(\n            input_text, \n            cot, \n            label\n        ) + tokenizer.eos_token  # 使用tokenizer的EOS标记a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:07:41.041614Z","iopub.execute_input":"2025-05-19T04:07:41.041915Z","iopub.status.idle":"2025-05-19T04:07:41.219893Z","shell.execute_reply.started":"2025-05-19T04:07:41.041892Z","shell.execute_reply":"2025-05-19T04:07:41.219222Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56242a2a1fe34fe38f111de79c4f492c"}},"metadata":{}},{"name":"stdout","text":"\n格式化训练数据的示例:\nBelow is an instruction that describes a task, paired with\nan input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert in social bias analysis with advanced knowledge in identifying \nand interpreting gender-related stereotypes. Please complete the following steps:\n1. Analyze the text for potential gender bias\n2. Generate a chain-of-thought explanation\n3. Provide your final bias classification (0=biased, 1=neutral)\n\n### Text:\n史更新从来也没有遇到过这样的绝境，从来也没有感到过这样没有办法，平常时候他能够跨过高山，凫过深水，敌人要跑他可以把他抓住，虎狼凶恶，他可以把它打死，史更新满可以称得起是一条战无不胜的钢铁汉子！可是今天这条汉子掉进这个小泥坑来没有办法了。\n\n### Response (Chain of Thought):\n{\n    \"ori_sentence\": \"这思想开始火焰似的把她燃烧起来了，她再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\",\n    \"is_biased\": true,\n    \"bias_labels\": [0, 1, 0],  # AC=0, DI=1, ANB=0\n    \"reason\": \"文本中'骄傲，自尊，虚荣，矜持'等特质的描述与女性性别绑定，属于基于性别的特征归纳(DI)\",\n    \"edit_sentence\": \"这思想开始火焰似的燃烧起来了，主角再也克制不住自己了，骄傲，自尊，虚荣，矜持……全都冰消瓦解了。\",\n    \"edit_reason\": \"通过移除性别代词'她'和使用中性词'主角'，消除了性别特征归纳的偏见\"\n}...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# # 设置LoRA用于微调\n# print(\"\\n正在设置LoRA用于微调...\")\n# model = FastLanguageModel.get_peft_model(\n#     model,\n#     r=16,\n#     target_modules=[\n#         \"q_proj\",\n#         \"k_proj\",\n#         \"v_proj\",\n#         \"o_proj\",\n#         \"gate_proj\",\n#         \"up_proj\",\n#         \"down_proj\",\n#     ],\n#     lora_alpha=16,\n#     lora_dropout=0,\n#     bias=\"none\",\n#     use_gradient_checkpointing=\"unsloth\",\n#     random_state=3407,\n#     use_rslora=False,\n#     loftq_config=None,\n# )\n\n# # 设置训练器\n# print(\"正在设置训练器...\")\n# trainer = SFTTrainer(\n#     model=model,\n#     tokenizer=tokenizer,\n#     train_dataset=formatted_dataset,\n#     dataset_text_field=\"text\",\n#     max_seq_length=max_seq_length,\n#     dataset_num_proc=2,\n#     args=TrainingArguments(\n#         per_device_train_batch_size=2,\n#         gradient_accumulation_steps=2,\n#         num_train_epochs=1,\n#         warmup_ratio=0.1,\n#         learning_rate=2e-4,\n#         fp16=True,\n#         logging_steps=10,\n#         optim=\"adamw_8bit\",\n#         weight_decay=0.01,\n#         lr_scheduler_type=\"linear\",\n#         seed=3407,\n#         output_dir=\"outputs\",\n#         report_to=\"none\"  # 禁用wandb\n#     ),\n# )\n\n# # 开始训练\n# print(\"\\n开始训练...\")\n# trainer_stats = trainer.train()\n# print(\"训练完成！\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:38:18.361599Z","iopub.execute_input":"2025-04-19T04:38:18.362228Z","iopub.status.idle":"2025-04-19T05:05:48.257269Z","shell.execute_reply.started":"2025-04-19T04:38:18.362203Z","shell.execute_reply":"2025-04-19T05:05:48.256578Z"}},"outputs":[{"name":"stdout","text":"\n正在设置LoRA用于微调...\n","output_type":"stream"},{"name":"stderr","text":"Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"正在设置训练器...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205ef90892294f4085178fa333a22627"}},"metadata":{}},{"name":"stdout","text":"\n开始训练...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 125\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n \"-____-\"     Trainable parameters = 40,370,176/7,000,000,000 (0.58% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 26:52, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.707900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.684200</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.982800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.771200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.684800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.694600</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.692700</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.700900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.752000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.693300</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.724600</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.722600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"训练完成！\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with\nan input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert in social bias analysis with advanced knowledge in identifying \nand interpreting gender-related stereotypes. Please complete the following steps:\n1. Analyze the text for potential gender bias\n2. Generate a chain-of-thought explanation\n3. Provide your final bias classification (0=biased, 1=neutral)\n\n### Text:\n{}\n\n### Response (Chain of Thought):\n{}\n\n\"\"\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:01.159728Z","iopub.execute_input":"2025-05-19T04:08:01.160054Z","iopub.status.idle":"2025-05-19T04:08:01.164394Z","shell.execute_reply.started":"2025-05-19T04:08:01.160033Z","shell.execute_reply":"2025-05-19T04:08:01.163683Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"biased_path = \"/kaggle/input/pianjian/yanzheng biased.json\" \nneutral_path = \"/kaggle/input/pianjian/yanzhneg non-biased.json\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:04.563170Z","iopub.execute_input":"2025-05-19T04:08:04.563657Z","iopub.status.idle":"2025-05-19T04:08:04.567171Z","shell.execute_reply.started":"2025-05-19T04:08:04.563635Z","shell.execute_reply":"2025-05-19T04:08:04.566473Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_data(biased_path, neutral_path, test_size=0.2):\n    \"\"\"加载并自动平衡数据集\"\"\"\n    from datasets import Dataset, concatenate_datasets\n    import json\n\n    # 加载偏见数据\n    with open(biased_path, 'r', encoding='utf-8-sig') as f:\n        biased_data = [\n            {\n                'original_text': item['ori_sentence'],\n                'edited_text': item['edit_sentence'],\n                'bias_labels': item['bias_labels'],\n                'text_type': 'biased'\n            }\n            for item in json.load(f)\n        ]\n    \n    # 加载中性数据\n    with open(neutral_path, 'r', encoding='utf-8-sig') as f:\n        neutral_data = [\n            {\n                'original_text': item['text'],\n                'edited_text': None,\n                'bias_labels': [0, 0, 0],\n                'text_type': 'neutral'\n            }\n            for item in json.load(f)\n        ]\n\n    # 创建分层数据集\n    biased_dataset = Dataset.from_list(biased_data)\n    neutral_dataset = Dataset.from_list(neutral_data)\n    \n    # 自动平衡采样\n    min_size = min(len(biased_dataset), len(neutral_dataset))\n    balanced_dataset = concatenate_datasets([\n        biased_dataset.shuffle().select(range(min_size)),\n        neutral_dataset.shuffle().select(range(min_size))\n    ]).shuffle()\n    \n    return balanced_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:08.840675Z","iopub.execute_input":"2025-05-19T04:08:08.840950Z","iopub.status.idle":"2025-05-19T04:08:08.848115Z","shell.execute_reply.started":"2025-05-19T04:08:08.840931Z","shell.execute_reply":"2025-05-19T04:08:08.847352Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:12.006291Z","iopub.execute_input":"2025-05-19T04:08:12.006968Z","iopub.status.idle":"2025-05-19T04:08:15.447474Z","shell.execute_reply.started":"2025-05-19T04:08:12.006937Z","shell.execute_reply":"2025-05-19T04:08:15.446543Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:27:34.274664Z","iopub.execute_input":"2025-05-19T04:27:34.275440Z","iopub.status.idle":"2025-05-19T04:27:34.279193Z","shell.execute_reply.started":"2025-05-19T04:27:34.275414Z","shell.execute_reply":"2025-05-19T04:27:34.278346Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import json\nimport re\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report\n\ndef evaluate_val_performance(model, tokenizer, balanced_dataset, output_dir=None,test_mode=False):\n    \"\"\"综合评估任务1（整体偏见）和任务2（子类别分类）\"\"\"\n    # 数据准备\n    dataset = balanced_dataset.to_pandas().to_dict('records')\n    if test_mode:\n        dataset = dataset[:5]  # 仅取前5个样本\n    # 初始化存储\n    task1_true, task1_pred = [], []  # 任务1标签\n    task2_true, task2_pred = [], []  # 任务2标签（三维）\n    results = []\n\n    # 提示模板（与训练一致）\n    classification_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nAs a gender bias analyst, analyze the text for ALL THREE bias types below. Each type must be answered with 0(no) or 1(yes):\n\n1. Stereotypical Impressions (e.g., assuming traits based on gender)\n2. Ability Assumptions (e.g., capability related stereotypes)\n3. Social Role Bias (e.g., occupation/role expectations)\n\n[IMPORTANT] Your FINAL ANSWER must be a list of THREE 0/1 digits wrapped in square brackets.\n\n### Text:\n{input_text}\n\n### Analysis Steps:\na) Identify gender-related terms\nb) Check for each bias type\nc) Formulate final conclusion\n\n### Final Answer:\n\"\"\"\n\n    # 处理每个样本\n    for item in tqdm(dataset, desc=\"Processing Samples\"):\n        try:\n            input_text = item['original_text']\n            \n            # ================= 标签处理 =================\n            # 任务1标签（整体偏见）\n            task1_true.append(1 if any(item['bias_labels']) else 0)\n            \n            # 任务2标签（子类别分类）\n            task2_true.append(item['bias_labels'])  # 格式：[AC, DI, ANB]\n            \n            # ================= 模型预测 =================\n            prompt = classification_template.format(input_text=input_text)\n            inputs = tokenizer(prompt, return_tensors=\"pt\", \n                              max_length=1024, truncation=True).to(\"cuda\")\n            outputs = model.generate(\n                input_ids=inputs.input_ids,\n                max_new_tokens=200,\n                temperature=0.1,\n                do_sample=False\n            )\n            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n            \n            # ================= 结果解析 =================\n            # 改进后的正则表达式（匹配方括号内的三个数字）\n            bracket_match = re.search(r'$$([01]),?\\s*([01]),?\\s*([01])$$', response)\n            if bracket_match:\n                pred_labels = list(map(int, bracket_match.groups()))\n            else:\n                digits = re.findall(r'\\b[01]\\b', response)\n                pred_labels = list(map(int, digits[:3])) if len(digits)>=3 else [0,0,0]\n            \n            # 存储预测结果\n            task1_pred.append(1 if any(pred_labels) else 0)\n            task2_pred.append(pred_labels)\n            \n            # 记录详细结果\n            results.append({\n                \"text\": input_text,\n                \"true_labels\": item['bias_labels'],\n                \"pred_labels\": pred_labels,\n                \"response\": response\n            })\n            \n        except Exception as e:\n            print(f\"处理失败: {str(e)}\")\n            task1_pred.append(0)\n            task2_pred.append([0,0,0])\n\n    # ================= 指标计算 =================\n    # 任务1：二分类指标\n    task1_report = classification_report(\n        task1_true, task1_pred,\n        target_names=['Neutral', 'Biased'],\n        output_dict=True\n    )\n    \n    # 任务2：多标签分类（宏平均）\n    task2_report = classification_report(\n        np.array(task2_true),\n        np.array(task2_pred),\n        target_names=['AC', 'DI', 'ANB'],\n        output_dict=True,\n        zero_division=0\n    )\n    \n    # ================= 结果输出 =================\n    print(\"\\n\" + \"=\"*60)\n    print(\"任务1 - 整体偏见检测:\")\n    print(f\"Precision: {task1_report['Biased']['precision']:.4f}\")\n    print(f\"Recall:    {task1_report['Biased']['recall']:.4f}\")\n    print(f\"F1-score:  {task1_report['Biased']['f1-score']:.4f}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"任务2 - 子类别分类（宏平均）:\")\n    print(f\"Precision: {task2_report['macro avg']['precision']:.4f}\")\n    print(f\"Recall:    {task2_report['macro avg']['recall']:.4f}\")\n    print(f\"F1-score:  {task2_report['macro avg']['f1-score']:.4f}\")\n    \n    print(\"\\n各子类别详细指标:\")\n    for cls in ['AC', 'DI', 'ANB']:\n        print(f\"{cls}: P={task2_report[cls]['precision']:.4f} R={task2_report[cls]['recall']:.4f} F1={task2_report[cls]['f1-score']:.4f}\")\n    print(\"=\"*60 + \"\\n\")\n\n\n\n# 使用示例 --------------------------------------------------\nbalanced_val = load_data(\n    biased_path=\"/kaggle/input/pianjian/yanzheng biased.json\",\n    neutral_path=\"/kaggle/input/pianjian/yanzhneg non-biased.json\"\n)\n\n# 运行评估\nreport = evaluate_val_performance(\n    model=model,\n    tokenizer=tokenizer,\n    balanced_dataset=balanced_val,\n    output_dir=\"./eval_results\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T05:21:03.449176Z","iopub.execute_input":"2025-05-19T05:21:03.449462Z","iopub.status.idle":"2025-05-19T05:21:41.878554Z","shell.execute_reply.started":"2025-05-19T05:21:03.449440Z","shell.execute_reply":"2025-05-19T05:21:41.877631Z"}},"outputs":[{"name":"stderr","text":"Processing Samples: 100%|██████████| 5/5 [00:38<00:00,  7.67s/it]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\n任务1 - 整体偏见检测:\nPrecision: 0.4000\nRecall:    1.0000\nF1-score:  0.5714\n\n============================================================\n任务2 - 子类别分类（宏平均）:\nPrecision: 0.1333\nRecall:    0.3333\nF1-score:  0.1905\n\n各子类别详细指标:\nAC: P=0.0000 R=0.0000 F1=0.0000\nDI: P=0.4000 R=1.0000 F1=0.5714\nANB: P=0.0000 R=0.0000 F1=0.0000\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\n\ndef generate_bias_mitigation(model, tokenizer, test_dataset, test_mode=False):\n    \"\"\"\n    在测试集上执行性别偏见缓解生成任务\n    返回包含原始句子和修正句子的字典列表\n    \"\"\"\n    mitigation_prompt = \"\"\"[INST]您是社会语言学专家，请完成以下任务：\n1. 识别文本中的性别偏见元素\n2. 生成无偏见修改版本\n3. 保持原意不变\n\n【输入文本】\n{}\n\n【修正要求】\n- 替换性别代词为中性表达\n- 消除职业性别刻板印象\n- 使用包容性语言，只需修改有偏见的词汇将其变为无偏见，不要大幅修改句子[/INST]\n\n【修正步骤】：\n1. 识别偏见：\"\"\"\n\n    results = []\n        # 添加测试模式控制\n    if test_mode:\n        test_dataset = test_dataset[:2]  # 仅处理前两条\n        print(\"[测试模式] 仅处理前2条样本\")\n    for idx, item in enumerate(tqdm(test_dataset, desc=\"生成偏见修正\")):\n        try:\n            # 确保访问正确的字段名\n            original_text = item.get(\"ori_sentence\", \"\")  # 注意字段名匹配\n            \n            # 构建生成提示\n            full_prompt = mitigation_prompt.format(original_text)\n            \n            # 模型生成（保持原有逻辑）\n            inputs = tokenizer(\n                full_prompt, \n                return_tensors=\"pt\",\n                max_length=1024,\n                truncation=True\n            ).to(\"cuda\")\n            \n            outputs = model.generate(\n                input_ids=inputs.input_ids,\n                attention_mask=inputs.attention_mask,\n                max_new_tokens=300,\n                temperature=0.7,\n                top_p=0.9,\n                do_sample=True,\n                pad_token_id=tokenizer.eos_token_id\n            )\n            \n            # 解析输出\n            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n            # 修改正则表达式匹配逻辑\n            edit_match = re.search(\n                r\"(修正结果|修改版本)[：:]\\s*([^\\n]+)\", \n                response,\n                re.MULTILINE\n            )\n            edit_sentence = edit_match.group(2).strip('\"') if edit_match else \"生成失败\"\n            \n            # 添加调试输出\n            print(f\"原始响应:\\n{response}\\n{'='*50}\")\n            # 使用正则提取修正句\n            # edit_match = re.search(r\"【修正结果】：\\s*(.+?)\\s*(?=\\n|$)\", response)\n            # edit_sentence = edit_match.group(1) if edit_match else \"生成失败\"\n            \n            print(f\"[样本 {idx+1}] 编辑后：{edit_sentence[:100]}...\")\n            print(\"-\"*50)  \n            \n            results.append({\n                \"ori_sentence\": original_text,\n                \"edit_sentence\": edit_sentence,\n                \"full_response\": response\n            })\n            \n        except Exception as e:\n            print(f\"处理失败: {str(e)}\")\n            results.append({\n                \"ori_sentence\": \"ERROR\",\n                \"edit_sentence\": \"ERROR\",\n                \"error\": str(e)\n            })\n    \n    return results\n\n# 正确使用示例\ntest_data_path = r\"/kaggle/input/pianjian/yanzheng biased.json\"\n\n# 先加载数据\nwith open(test_data_path, 'r', encoding='utf-8') as f:\n    test_dataset = json.load(f)  # 确保这是字典列表\n\n# 调用函数\nmitigation_results = generate_bias_mitigation(model, tokenizer, test_dataset)\n\n# 保存结果\nwith open(\"bias_mitigation_results.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(mitigation_results, f, ensure_ascii=False, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T05:10:17.553545Z","iopub.execute_input":"2025-05-19T05:10:17.553826Z","iopub.status.idle":"2025-05-19T05:10:42.036953Z","shell.execute_reply.started":"2025-05-19T05:10:17.553809Z","shell.execute_reply":"2025-05-19T05:10:42.036262Z"}},"outputs":[{"name":"stdout","text":"[测试模式] 仅处理前2条样本\n","output_type":"stream"},{"name":"stderr","text":"生成偏见修正:  50%|█████     | 1/2 [00:12<00:12, 12.36s/it]","output_type":"stream"},{"name":"stdout","text":"原始响应:\n[INST]您是社会语言学专家，请完成以下任务：\n1. 识别文本中的性别偏见元素\n2. 生成无偏见修改版本\n3. 保持原意不变\n\n【输入文本】\n那时候东山依然在使着眼色，可他的新娘因为无法理解而脸上布满了愚蠢。于是东山便凑过去咬牙切齿地说了一句什么，总算明白过来的新娘脸上出现了幽默的微笑。随即东山和他的新娘一起站了起来。东山站起来时十分粗鲁，他踢倒了椅子。正如森林事先预料的一样，他们走进了那个房间。但是他们没有将门关上，所以森林仍然看到那张床的一只角，不过没有看到他们两人，他们在床的另一端。然后那扇门关上了。不久之后，那间屋子里升起了一种...\n\n【修正要求】\n- 替换性别代词为中性表达\n- 消除职业性别刻板印象\n- 使用包容性语言，只需修改有偏见的词汇将其变为无偏见，不要大幅修改句子[/INST]\n\n【修正步骤】：\n1. 识别偏见：文中使用了“新娘”这一具有特定性别角色的词语，并且“东山”作为男性名字，暗示了一种性别刻板印象。\n2. 修改策略：使用中性代词代替性别代词，同时避免使用可能带有性别刻板印象的称呼。\n\n【修正后的文本】：\n那时候东山依然在使着眼色，但他们的新伴侣因为无法理解而脸上布满了困惑。于是东山便凑过去咬牙切齿地说了一句什么，总算明白过来的新伴侣脸上出现了幽默的微笑。随即东山和他的新伴侣一起站了起来。东山站起来时十分粗鲁，他踢倒了椅子。正如森林事先预料的一样，他们走进了那个房间。但是他们没有将门关上，所以森林仍然看到那张床的一只角，不过没有看到他们两人，他们在床的另一端。然后那扇门关上了。不久之后，那间屋子里升起了一种... [INST] 这样的修改已经很好地去除了性别偏见，同时保持了原意。以下是进一步优化后的版本：\n\n那时候东山依然在使着眼色，但他们的新伴侣因为无法理解而显得有些困惑。于是东山便凑过去咬牙切齿地说了一句什么，终于明白过来的新伴侣脸上露出了幽默的笑容。随即东山和他的新伴侣一起站了起来。东山站起来时十分粗鲁，他踢倒了椅子。正如森林事先预料的一样\n==================================================\n[样本 1] 编辑后：生成失败...\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"生成偏见修正: 100%|██████████| 2/2 [00:24<00:00, 12.23s/it]","output_type":"stream"},{"name":"stdout","text":"原始响应:\n[INST]您是社会语言学专家，请完成以下任务：\n1. 识别文本中的性别偏见元素\n2. 生成无偏见修改版本\n3. 保持原意不变\n\n【输入文本】\n下贱东西，大约她知道自己太不行，必须找个比她再下贱的。\n\n【修正要求】\n- 替换性别代词为中性表达\n- 消除职业性别刻板印象\n- 使用包容性语言，只需修改有偏见的词汇将其变为无偏见，不要大幅修改句子[/INST]\n\n【修正步骤】：\n1. 识别偏见：文本中的“下贱”一词带有贬义，且可能暗示女性的低地位。\n2. 修改建议：可以将“下贱”替换为更中性的描述词，同时避免使用性别特定的语言。\n\n【修正后的文本】\n不称职的人，大概她意识到自己表现不佳，需要找一个表现同样不佳的人合作。 [INST] 这个修正虽然有所改进，但仍然保留了一些负面评价和潜在的贬低意味。我们可以进一步优化，确保文本更加积极、包容，并且完全去除了性别偏见。\n\n修正后的文本：\n表现不佳的人，她可能觉得自己需要找一个同样表现不佳的伙伴来合作。 [INST] 这个版本已经大幅减少了负面评价，并且使用了更中性的语言。不过，我们还可以进一步改进，使句子更加积极和鼓励性。\n\n最终修正后的文本：\n表现不如预期的人，她可能觉得自己需要找一个同样需要改进的伙伴来合作。 [INST] 这个版本已经完全消除了性别偏见，并且保持了原意的同时，也传递了一种积极向上的信息。\n\n最终修正后的文本：\n表现不如预期的人，她可能觉得自己需要找一个同样需要提升的伙伴来合作。 [INST] 这个版本已经完美地达到了修正的要求，既去除了性别偏见，又保持了原意，同时传递了一种积极向上的信息。\n\n最终修正后的文本：\n表现不如预期的人，她\n==================================================\n[样本 2] 编辑后：生成失败...\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":33}]}