{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11081302,"sourceType":"datasetVersion","datasetId":6888932},{"sourceId":11458156,"sourceType":"datasetVersion","datasetId":7179473}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install unsloth","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:01:05.358683Z","iopub.execute_input":"2025-05-19T04:01:05.358949Z","iopub.status.idle":"2025-05-19T04:04:16.094577Z","shell.execute_reply.started":"2025-05-19T04:01:05.358931Z","shell.execute_reply":"2025-05-19T04:04:16.093845Z"}},"outputs":[{"name":"stdout","text":"Collecting unsloth\n  Downloading unsloth-2025.5.6-py3-none-any.whl.metadata (46 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting unsloth_zoo>=2025.5.7 (from unsloth)\n  Downloading unsloth_zoo-2025.5.7-py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\nCollecting xformers>=0.0.27.post2 (from unsloth)\n  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\nCollecting bitsandbytes (from unsloth)\n  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\nRequirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (25.0)\nCollecting tyro (from unsloth)\n  Downloading tyro-0.9.20-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: transformers!=4.47.0,==4.51.3 in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.51.3)\nRequirement already satisfied: datasets>=3.4.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.6.0)\nRequirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (7.0.0)\nRequirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\nRequirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.5.2)\nCollecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.14.0)\nRequirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.20.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.31.1)\nRequirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\nRequirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.2)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (3.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers!=4.47.0,==4.51.3->unsloth) (0.5.3)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.13.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (1.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->unsloth) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (14.0.0)\nCollecting cut_cross_entropy (from unsloth_zoo>=2025.5.7->unsloth)\n  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.5.7->unsloth) (11.1.0)\nCollecting msgspec (from unsloth_zoo>=2025.5.7->unsloth)\n  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\nCollecting torch>=2.4.0 (from unsloth)\n  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\nCollecting sympy>=1.13.3 (from torch>=2.4.0->unsloth)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nCollecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch>=2.4.0->unsloth)\n  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.3.0.4 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.7.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparselt-cu12==0.6.3 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting nvidia-nccl-cu12==2.26.2 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.6.77 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch>=2.4.0->unsloth)\n  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufile-cu12==1.11.1.6 (from torch>=2.4.0->unsloth)\n  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\nCollecting triton>=3.0.0 (from unsloth)\n  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\nINFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\nCollecting torchvision (from unsloth)\n  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\nRequirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\nCollecting shtab>=1.5.6 (from tyro->unsloth)\n  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\nRequirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (3.11.18)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth) (2025.4.26)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.19.1)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->unsloth) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->unsloth) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.20.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->unsloth) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.17.0)\nDownloading unsloth-2025.5.6-py3-none-any.whl (265 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m265.6/265.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading unsloth_zoo-2025.5.7-py3-none-any.whl (138 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tyro-0.9.20-py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\nDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m103.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\nDownloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, cut_cross_entropy, trl, xformers, unsloth_zoo, torchvision, bitsandbytes, unsloth\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127\n    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.127\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.4.127\n    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: torch\n    Found existing installation: torch 2.6.0+cu124\n    Uninstalling torch-2.6.0+cu124:\n      Successfully uninstalled torch-2.6.0+cu124\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.21.0+cu124\n    Uninstalling torchvision-0.21.0+cu124:\n      Successfully uninstalled torchvision-0.21.0+cu124\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.45.5 cut_cross_entropy-25.1.1 fsspec-2025.3.0 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 shtab-1.7.2 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0 trl-0.15.2 tyro-0.9.20 unsloth-2025.5.6 unsloth_zoo-2025.5.7 xformers-0.0.30\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\n# æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å­˜åœ¨\ndataset_path = \"/kaggle/input/pianjian\"\nif os.path.exists(dataset_path):\n    print(\"âœ… æ•°æ®é›†ç›®å½•å­˜åœ¨\")\n    print(\"ç›®å½•å†…å®¹:\", os.listdir(dataset_path))\nelse:\n    print(f\"âŒ è·¯å¾„é”™è¯¯: {dataset_path} ä¸å­˜åœ¨\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:04:33.812415Z","iopub.execute_input":"2025-05-19T04:04:33.812724Z","iopub.status.idle":"2025-05-19T04:04:33.820767Z","shell.execute_reply.started":"2025-05-19T04:04:33.812696Z","shell.execute_reply":"2025-05-19T04:04:33.819946Z"}},"outputs":[{"name":"stdout","text":"âœ… æ•°æ®é›†ç›®å½•å­˜åœ¨\nç›®å½•å†…å®¹: ['ceshi biased.json', 'yanzheng biased.json', 'non-biased.json', 'biased.json', 'yanzhneg non-biased.json', 'ceshi non-biased.json']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# ç¤ºä¾‹è„šæœ¬ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ¥è‡ªHugging Faceçš„æ€ç»´é“¾(COT)æ•°æ®é›†\n\nimport torch\nfrom unsloth import FastLanguageModel\nfrom datasets import load_dataset\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments\nfrom tqdm import tqdm\nimport re\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:04:37.396624Z","iopub.execute_input":"2025-05-19T04:04:37.396859Z","iopub.status.idle":"2025-05-19T04:05:10.150518Z","shell.execute_reply.started":"2025-05-19T04:04:37.396844Z","shell.execute_reply":"2025-05-19T04:05:10.149909Z"}},"outputs":[{"name":"stdout","text":"ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2025-05-19 04:04:48.152287: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747627488.379036      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747627488.437436      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ç›´æ¥ä»Hugging FaceåŠ è½½COTæ•°æ®é›†\nprint(\"æ­£åœ¨ä»Hugging FaceåŠ è½½COTæ•°æ®é›†...\")\n# enhanced_dataset = load_dataset(dataset_name, split=\"train\")\n\nHF_TOKEN = \"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\"  \n\n# æ˜ç¡®æŒ‡å®šæ•°æ®è·¯å¾„å’Œä»¤ç‰Œ\nenhanced_dataset = load_dataset(\n    \"pianjian/pianjian-with-cot\",\n    data_dir=\"data\",  \n    split=\"train\",\n    token=HF_TOKEN  # å…³é”®ï¼šæ·»åŠ ç§æœ‰æ•°æ®é›†è®¿é—®æƒé™\n)\nprint(f\"å·²åŠ è½½{len(enhanced_dataset)}ä¸ªå¸¦æœ‰æ€ç»´é“¾æ¨ç†çš„ç¤ºä¾‹\")\n# åˆå§‹åŒ–æ¨¡å‹\nmax_seq_length = 2048\ndtype = torch.float16  # ç”¨äº4ä½é‡åŒ–\nload_in_4bit = True\n\nprint(\"æ­£åœ¨åŠ è½½æ¨¡å‹...\")\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name=\"unsloth/Qwen2.5-7B-Instruct\",\n    max_seq_length=max_seq_length,\n    dtype=dtype,\n    load_in_4bit=load_in_4bit,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:05:20.831886Z","iopub.execute_input":"2025-05-19T04:05:20.832949Z","iopub.status.idle":"2025-05-19T04:06:13.552328Z","shell.execute_reply.started":"2025-05-19T04:05:20.832925Z","shell.execute_reply":"2025-05-19T04:06:13.551741Z"}},"outputs":[{"name":"stdout","text":"æ­£åœ¨ä»Hugging FaceåŠ è½½COTæ•°æ®é›†...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/448 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"545b34c9d9684f9bb8b742f6ae372cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/550k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716b61cfbc4f4288915e40bd0c1dbce6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"057729301de54c6d8dc3fc2aa3f32b4b"}},"metadata":{}},{"name":"stdout","text":"å·²åŠ è½½1000ä¸ªå¸¦æœ‰æ€ç»´é“¾æ¨ç†çš„ç¤ºä¾‹\næ­£åœ¨åŠ è½½æ¨¡å‹...\n==((====))==  Unsloth 2025.5.6: Fast Qwen2 patching. Transformers: 4.51.3.\n   \\\\   /|    Tesla P100-PCIE-16GB. Num GPUs = 1. Max memory: 15.888 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 6.0. CUDA Toolkit: 12.6. Triton: 3.3.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/112k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98de83aeb3214b78806a0d595a441f1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b28152c170ff4be188a51ee175a432ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba6f36eb473749ec8986198d31f81553"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"894a67ccf81e4df4974b0ad68a53b1d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"936d38f31570432cb7e635e834a6a692"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.36k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"125ebe9de90748dfa2a31350465c2b33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0401336e55d242c69e82075a843478b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dc7da486f064c679990c69dc0937612"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51fd4343a75447a3bf7aee00defb92d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0360fa2b7fbf42128ddbe7e7f976036a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad9c1253042410987575bdd3e3d046d"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# ä¿®æ”¹åçš„è®­ç»ƒæç¤ºæ¨¡æ¿ï¼ˆå¢å¼ºé€»è¾‘ä¸€è‡´æ€§ï¼‰\ntrain_prompt_style = \"\"\"Below is an instruction that describes a task, paired with\nan input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert in social bias analysis with advanced knowledge in identifying \nand interpreting gender-related stereotypes. Please complete the following steps:\n1. Analyze the text for potential gender bias\n2. Generate a chain-of-thought explanation\n3. Provide your final bias classification (0=biased, 1=neutral)\n\n### Text:\n{}\n\n### Response (Chain of Thought):\n{}\n\n### Final Answer:\n{}\"\"\"  # ä¿®æ”¹ä¸ºäºŒå…ƒåˆ†ç±»ä»»åŠ¡\n\n# å®šä¹‰æ ‡ç­¾è½¬æ¢å‡½æ•°ï¼ˆæ ¹æ®æ‚¨çš„ä¸šåŠ¡éœ€æ±‚è°ƒæ•´ï¼‰\ndef convert_label(bias_labels):\n    \"\"\"å°†ä¸‰ç»´åè§æ ‡ç­¾è½¬æ¢ä¸ºäºŒå…ƒåˆ†ç±»æ ‡ç­¾\"\"\"\n    # ç¤ºä¾‹é€»è¾‘ï¼šä»»ä¸€ç»´åº¦å­˜åœ¨åè§åˆ™æ ‡è®°ä¸º0ï¼Œä¸­æ€§ä¸º1\n    return 0 if sum(bias_labels) > 0 else 1\n\n# ä¿®æ”¹åçš„æ ¼å¼åŒ–å‡½æ•°\ndef formatting_prompts_func(examples):\n    inputs = examples[\"original_text\"]  # æ˜ å°„åŸå§‹å­—æ®µ\n    cots = examples[\"Bias_Analysis_CoT\"]\n    labels = [convert_label(l) for l in examples[\"bias_labels\"]]  # æ ‡ç­¾è½¬æ¢\n    \n    texts = []\n    for input_text, cot, label in zip(inputs, cots, labels):\n        formatted_text = train_prompt_style.format(\n            input_text, \n            cot, \n            label\n        ) + tokenizer.eos_token  # ä½¿ç”¨tokenizerçš„EOSæ ‡è®°a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:07:41.041614Z","iopub.execute_input":"2025-05-19T04:07:41.041915Z","iopub.status.idle":"2025-05-19T04:07:41.219893Z","shell.execute_reply.started":"2025-05-19T04:07:41.041892Z","shell.execute_reply":"2025-05-19T04:07:41.219222Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56242a2a1fe34fe38f111de79c4f492c"}},"metadata":{}},{"name":"stdout","text":"\næ ¼å¼åŒ–è®­ç»ƒæ•°æ®çš„ç¤ºä¾‹:\nBelow is an instruction that describes a task, paired with\nan input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert in social bias analysis with advanced knowledge in identifying \nand interpreting gender-related stereotypes. Please complete the following steps:\n1. Analyze the text for potential gender bias\n2. Generate a chain-of-thought explanation\n3. Provide your final bias classification (0=biased, 1=neutral)\n\n### Text:\nå²æ›´æ–°ä»æ¥ä¹Ÿæ²¡æœ‰é‡åˆ°è¿‡è¿™æ ·çš„ç»å¢ƒï¼Œä»æ¥ä¹Ÿæ²¡æœ‰æ„Ÿåˆ°è¿‡è¿™æ ·æ²¡æœ‰åŠæ³•ï¼Œå¹³å¸¸æ—¶å€™ä»–èƒ½å¤Ÿè·¨è¿‡é«˜å±±ï¼Œå‡«è¿‡æ·±æ°´ï¼Œæ•Œäººè¦è·‘ä»–å¯ä»¥æŠŠä»–æŠ“ä½ï¼Œè™ç‹¼å‡¶æ¶ï¼Œä»–å¯ä»¥æŠŠå®ƒæ‰“æ­»ï¼Œå²æ›´æ–°æ»¡å¯ä»¥ç§°å¾—èµ·æ˜¯ä¸€æ¡æˆ˜æ— ä¸èƒœçš„é’¢é“æ±‰å­ï¼å¯æ˜¯ä»Šå¤©è¿™æ¡æ±‰å­æ‰è¿›è¿™ä¸ªå°æ³¥å‘æ¥æ²¡æœ‰åŠæ³•äº†ã€‚\n\n### Response (Chain of Thought):\n{\n    \"ori_sentence\": \"è¿™æ€æƒ³å¼€å§‹ç«ç„°ä¼¼çš„æŠŠå¥¹ç‡ƒçƒ§èµ·æ¥äº†ï¼Œå¥¹å†ä¹Ÿå…‹åˆ¶ä¸ä½è‡ªå·±äº†ï¼Œéª„å‚²ï¼Œè‡ªå°Šï¼Œè™šè£ï¼ŒçŸœæŒâ€¦â€¦å…¨éƒ½å†°æ¶ˆç“¦è§£äº†ã€‚\",\n    \"is_biased\": true,\n    \"bias_labels\": [0, 1, 0],  # AC=0, DI=1, ANB=0\n    \"reason\": \"æ–‡æœ¬ä¸­'éª„å‚²ï¼Œè‡ªå°Šï¼Œè™šè£ï¼ŒçŸœæŒ'ç­‰ç‰¹è´¨çš„æè¿°ä¸å¥³æ€§æ€§åˆ«ç»‘å®šï¼Œå±äºåŸºäºæ€§åˆ«çš„ç‰¹å¾å½’çº³(DI)\",\n    \"edit_sentence\": \"è¿™æ€æƒ³å¼€å§‹ç«ç„°ä¼¼çš„ç‡ƒçƒ§èµ·æ¥äº†ï¼Œä¸»è§’å†ä¹Ÿå…‹åˆ¶ä¸ä½è‡ªå·±äº†ï¼Œéª„å‚²ï¼Œè‡ªå°Šï¼Œè™šè£ï¼ŒçŸœæŒâ€¦â€¦å…¨éƒ½å†°æ¶ˆç“¦è§£äº†ã€‚\",\n    \"edit_reason\": \"é€šè¿‡ç§»é™¤æ€§åˆ«ä»£è¯'å¥¹'å’Œä½¿ç”¨ä¸­æ€§è¯'ä¸»è§’'ï¼Œæ¶ˆé™¤äº†æ€§åˆ«ç‰¹å¾å½’çº³çš„åè§\"\n}...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# # è®¾ç½®LoRAç”¨äºå¾®è°ƒ\n# print(\"\\næ­£åœ¨è®¾ç½®LoRAç”¨äºå¾®è°ƒ...\")\n# model = FastLanguageModel.get_peft_model(\n#     model,\n#     r=16,\n#     target_modules=[\n#         \"q_proj\",\n#         \"k_proj\",\n#         \"v_proj\",\n#         \"o_proj\",\n#         \"gate_proj\",\n#         \"up_proj\",\n#         \"down_proj\",\n#     ],\n#     lora_alpha=16,\n#     lora_dropout=0,\n#     bias=\"none\",\n#     use_gradient_checkpointing=\"unsloth\",\n#     random_state=3407,\n#     use_rslora=False,\n#     loftq_config=None,\n# )\n\n# # è®¾ç½®è®­ç»ƒå™¨\n# print(\"æ­£åœ¨è®¾ç½®è®­ç»ƒå™¨...\")\n# trainer = SFTTrainer(\n#     model=model,\n#     tokenizer=tokenizer,\n#     train_dataset=formatted_dataset,\n#     dataset_text_field=\"text\",\n#     max_seq_length=max_seq_length,\n#     dataset_num_proc=2,\n#     args=TrainingArguments(\n#         per_device_train_batch_size=2,\n#         gradient_accumulation_steps=2,\n#         num_train_epochs=1,\n#         warmup_ratio=0.1,\n#         learning_rate=2e-4,\n#         fp16=True,\n#         logging_steps=10,\n#         optim=\"adamw_8bit\",\n#         weight_decay=0.01,\n#         lr_scheduler_type=\"linear\",\n#         seed=3407,\n#         output_dir=\"outputs\",\n#         report_to=\"none\"  # ç¦ç”¨wandb\n#     ),\n# )\n\n# # å¼€å§‹è®­ç»ƒ\n# print(\"\\nå¼€å§‹è®­ç»ƒ...\")\n# trainer_stats = trainer.train()\n# print(\"è®­ç»ƒå®Œæˆï¼\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T04:38:18.361599Z","iopub.execute_input":"2025-04-19T04:38:18.362228Z","iopub.status.idle":"2025-04-19T05:05:48.257269Z","shell.execute_reply.started":"2025-04-19T04:38:18.362203Z","shell.execute_reply":"2025-04-19T05:05:48.256578Z"}},"outputs":[{"name":"stdout","text":"\næ­£åœ¨è®¾ç½®LoRAç”¨äºå¾®è°ƒ...\n","output_type":"stream"},{"name":"stderr","text":"Unsloth 2025.3.19 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"},{"name":"stdout","text":"æ­£åœ¨è®¾ç½®è®­ç»ƒå™¨...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"205ef90892294f4085178fa333a22627"}},"metadata":{}},{"name":"stdout","text":"\nå¼€å§‹è®­ç»ƒ...\n","output_type":"stream"},{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 125\nO^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 2\n\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 2 x 1) = 8\n \"-____-\"     Trainable parameters = 40,370,176/7,000,000,000 (0.58% trained)\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Will smartly offload gradients to save VRAM!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 26:52, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.707900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.684200</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.982800</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.771200</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.684800</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.694600</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.692700</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.700900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.752000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.693300</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.724600</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.722600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"è®­ç»ƒå®Œæˆï¼\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"prompt_style = \"\"\"Below is an instruction that describes a task, paired with\nan input that provides further context. \nWrite a response that appropriately completes the request.\n\n### Instruction:\nYou are an expert in social bias analysis with advanced knowledge in identifying \nand interpreting gender-related stereotypes. Please complete the following steps:\n1. Analyze the text for potential gender bias\n2. Generate a chain-of-thought explanation\n3. Provide your final bias classification (0=biased, 1=neutral)\n\n### Text:\n{}\n\n### Response (Chain of Thought):\n{}\n\n\"\"\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:01.159728Z","iopub.execute_input":"2025-05-19T04:08:01.160054Z","iopub.status.idle":"2025-05-19T04:08:01.164394Z","shell.execute_reply.started":"2025-05-19T04:08:01.160033Z","shell.execute_reply":"2025-05-19T04:08:01.163683Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"biased_path = \"/kaggle/input/pianjian/yanzheng biased.json\" \nneutral_path = \"/kaggle/input/pianjian/yanzhneg non-biased.json\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:04.563170Z","iopub.execute_input":"2025-05-19T04:08:04.563657Z","iopub.status.idle":"2025-05-19T04:08:04.567171Z","shell.execute_reply.started":"2025-05-19T04:08:04.563635Z","shell.execute_reply":"2025-05-19T04:08:04.566473Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def load_data(biased_path, neutral_path, test_size=0.2):\n    \"\"\"åŠ è½½å¹¶è‡ªåŠ¨å¹³è¡¡æ•°æ®é›†\"\"\"\n    from datasets import Dataset, concatenate_datasets\n    import json\n\n    # åŠ è½½åè§æ•°æ®\n    with open(biased_path, 'r', encoding='utf-8-sig') as f:\n        biased_data = [\n            {\n                'original_text': item['ori_sentence'],\n                'edited_text': item['edit_sentence'],\n                'bias_labels': item['bias_labels'],\n                'text_type': 'biased'\n            }\n            for item in json.load(f)\n        ]\n    \n    # åŠ è½½ä¸­æ€§æ•°æ®\n    with open(neutral_path, 'r', encoding='utf-8-sig') as f:\n        neutral_data = [\n            {\n                'original_text': item['text'],\n                'edited_text': None,\n                'bias_labels': [0, 0, 0],\n                'text_type': 'neutral'\n            }\n            for item in json.load(f)\n        ]\n\n    # åˆ›å»ºåˆ†å±‚æ•°æ®é›†\n    biased_dataset = Dataset.from_list(biased_data)\n    neutral_dataset = Dataset.from_list(neutral_data)\n    \n    # è‡ªåŠ¨å¹³è¡¡é‡‡æ ·\n    min_size = min(len(biased_dataset), len(neutral_dataset))\n    balanced_dataset = concatenate_datasets([\n        biased_dataset.shuffle().select(range(min_size)),\n        neutral_dataset.shuffle().select(range(min_size))\n    ]).shuffle()\n    \n    return balanced_dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:08.840675Z","iopub.execute_input":"2025-05-19T04:08:08.840950Z","iopub.status.idle":"2025-05-19T04:08:08.848115Z","shell.execute_reply.started":"2025-05-19T04:08:08.840931Z","shell.execute_reply":"2025-05-19T04:08:08.847352Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:08:12.006291Z","iopub.execute_input":"2025-05-19T04:08:12.006968Z","iopub.status.idle":"2025-05-19T04:08:15.447474Z","shell.execute_reply.started":"2025-05-19T04:08:12.006937Z","shell.execute_reply":"2025-05-19T04:08:15.446543Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn) (2024.2.0)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T04:27:34.274664Z","iopub.execute_input":"2025-05-19T04:27:34.275440Z","iopub.status.idle":"2025-05-19T04:27:34.279193Z","shell.execute_reply.started":"2025-05-19T04:27:34.275414Z","shell.execute_reply":"2025-05-19T04:27:34.278346Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import json\nimport re\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import classification_report\n\ndef evaluate_val_performance(model, tokenizer, balanced_dataset, output_dir=None,test_mode=False):\n    \"\"\"ç»¼åˆè¯„ä¼°ä»»åŠ¡1ï¼ˆæ•´ä½“åè§ï¼‰å’Œä»»åŠ¡2ï¼ˆå­ç±»åˆ«åˆ†ç±»ï¼‰\"\"\"\n    # æ•°æ®å‡†å¤‡\n    dataset = balanced_dataset.to_pandas().to_dict('records')\n    if test_mode:\n        dataset = dataset[:5]  # ä»…å–å‰5ä¸ªæ ·æœ¬\n    # åˆå§‹åŒ–å­˜å‚¨\n    task1_true, task1_pred = [], []  # ä»»åŠ¡1æ ‡ç­¾\n    task2_true, task2_pred = [], []  # ä»»åŠ¡2æ ‡ç­¾ï¼ˆä¸‰ç»´ï¼‰\n    results = []\n\n    # æç¤ºæ¨¡æ¿ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰\n    classification_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instruction:\nAs a gender bias analyst, analyze the text for ALL THREE bias types below. Each type must be answered with 0(no) or 1(yes):\n\n1. Stereotypical Impressions (e.g., assuming traits based on gender)\n2. Ability Assumptions (e.g., capability related stereotypes)\n3. Social Role Bias (e.g., occupation/role expectations)\n\n[IMPORTANT] Your FINAL ANSWER must be a list of THREE 0/1 digits wrapped in square brackets.\n\n### Text:\n{input_text}\n\n### Analysis Steps:\na) Identify gender-related terms\nb) Check for each bias type\nc) Formulate final conclusion\n\n### Final Answer:\n\"\"\"\n\n    # å¤„ç†æ¯ä¸ªæ ·æœ¬\n    for item in tqdm(dataset, desc=\"Processing Samples\"):\n        try:\n            input_text = item['original_text']\n            \n            # ================= æ ‡ç­¾å¤„ç† =================\n            # ä»»åŠ¡1æ ‡ç­¾ï¼ˆæ•´ä½“åè§ï¼‰\n            task1_true.append(1 if any(item['bias_labels']) else 0)\n            \n            # ä»»åŠ¡2æ ‡ç­¾ï¼ˆå­ç±»åˆ«åˆ†ç±»ï¼‰\n            task2_true.append(item['bias_labels'])  # æ ¼å¼ï¼š[AC, DI, ANB]\n            \n            # ================= æ¨¡å‹é¢„æµ‹ =================\n            prompt = classification_template.format(input_text=input_text)\n            inputs = tokenizer(prompt, return_tensors=\"pt\", \n                              max_length=1024, truncation=True).to(\"cuda\")\n            outputs = model.generate(\n                input_ids=inputs.input_ids,\n                max_new_tokens=200,\n                temperature=0.1,\n                do_sample=False\n            )\n            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n            \n            # ================= ç»“æœè§£æ =================\n            # æ”¹è¿›åçš„æ­£åˆ™è¡¨è¾¾å¼ï¼ˆåŒ¹é…æ–¹æ‹¬å·å†…çš„ä¸‰ä¸ªæ•°å­—ï¼‰\n            bracket_match = re.search(r'$$([01]),?\\s*([01]),?\\s*([01])$$', response)\n            if bracket_match:\n                pred_labels = list(map(int, bracket_match.groups()))\n            else:\n                digits = re.findall(r'\\b[01]\\b', response)\n                pred_labels = list(map(int, digits[:3])) if len(digits)>=3 else [0,0,0]\n            \n            # å­˜å‚¨é¢„æµ‹ç»“æœ\n            task1_pred.append(1 if any(pred_labels) else 0)\n            task2_pred.append(pred_labels)\n            \n            # è®°å½•è¯¦ç»†ç»“æœ\n            results.append({\n                \"text\": input_text,\n                \"true_labels\": item['bias_labels'],\n                \"pred_labels\": pred_labels,\n                \"response\": response\n            })\n            \n        except Exception as e:\n            print(f\"å¤„ç†å¤±è´¥: {str(e)}\")\n            task1_pred.append(0)\n            task2_pred.append([0,0,0])\n\n    # ================= æŒ‡æ ‡è®¡ç®— =================\n    # ä»»åŠ¡1ï¼šäºŒåˆ†ç±»æŒ‡æ ‡\n    task1_report = classification_report(\n        task1_true, task1_pred,\n        target_names=['Neutral', 'Biased'],\n        output_dict=True\n    )\n    \n    # ä»»åŠ¡2ï¼šå¤šæ ‡ç­¾åˆ†ç±»ï¼ˆå®å¹³å‡ï¼‰\n    task2_report = classification_report(\n        np.array(task2_true),\n        np.array(task2_pred),\n        target_names=['AC', 'DI', 'ANB'],\n        output_dict=True,\n        zero_division=0\n    )\n    \n    # ================= ç»“æœè¾“å‡º =================\n    print(\"\\n\" + \"=\"*60)\n    print(\"ä»»åŠ¡1 - æ•´ä½“åè§æ£€æµ‹:\")\n    print(f\"Precision: {task1_report['Biased']['precision']:.4f}\")\n    print(f\"Recall:    {task1_report['Biased']['recall']:.4f}\")\n    print(f\"F1-score:  {task1_report['Biased']['f1-score']:.4f}\")\n    \n    print(\"\\n\" + \"=\"*60)\n    print(\"ä»»åŠ¡2 - å­ç±»åˆ«åˆ†ç±»ï¼ˆå®å¹³å‡ï¼‰:\")\n    print(f\"Precision: {task2_report['macro avg']['precision']:.4f}\")\n    print(f\"Recall:    {task2_report['macro avg']['recall']:.4f}\")\n    print(f\"F1-score:  {task2_report['macro avg']['f1-score']:.4f}\")\n    \n    print(\"\\nå„å­ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:\")\n    for cls in ['AC', 'DI', 'ANB']:\n        print(f\"{cls}: P={task2_report[cls]['precision']:.4f} R={task2_report[cls]['recall']:.4f} F1={task2_report[cls]['f1-score']:.4f}\")\n    print(\"=\"*60 + \"\\n\")\n\n\n\n# ä½¿ç”¨ç¤ºä¾‹ --------------------------------------------------\nbalanced_val = load_data(\n    biased_path=\"/kaggle/input/pianjian/yanzheng biased.json\",\n    neutral_path=\"/kaggle/input/pianjian/yanzhneg non-biased.json\"\n)\n\n# è¿è¡Œè¯„ä¼°\nreport = evaluate_val_performance(\n    model=model,\n    tokenizer=tokenizer,\n    balanced_dataset=balanced_val,\n    output_dir=\"./eval_results\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T05:21:03.449176Z","iopub.execute_input":"2025-05-19T05:21:03.449462Z","iopub.status.idle":"2025-05-19T05:21:41.878554Z","shell.execute_reply.started":"2025-05-19T05:21:03.449440Z","shell.execute_reply":"2025-05-19T05:21:41.877631Z"}},"outputs":[{"name":"stderr","text":"Processing Samples: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:38<00:00,  7.67s/it]","output_type":"stream"},{"name":"stdout","text":"\n============================================================\nä»»åŠ¡1 - æ•´ä½“åè§æ£€æµ‹:\nPrecision: 0.4000\nRecall:    1.0000\nF1-score:  0.5714\n\n============================================================\nä»»åŠ¡2 - å­ç±»åˆ«åˆ†ç±»ï¼ˆå®å¹³å‡ï¼‰:\nPrecision: 0.1333\nRecall:    0.3333\nF1-score:  0.1905\n\nå„å­ç±»åˆ«è¯¦ç»†æŒ‡æ ‡:\nAC: P=0.0000 R=0.0000 F1=0.0000\nDI: P=0.4000 R=1.0000 F1=0.5714\nANB: P=0.0000 R=0.0000 F1=0.0000\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import json\nfrom tqdm import tqdm\n\ndef generate_bias_mitigation(model, tokenizer, test_dataset, test_mode=False):\n    \"\"\"\n    åœ¨æµ‹è¯•é›†ä¸Šæ‰§è¡Œæ€§åˆ«åè§ç¼“è§£ç”Ÿæˆä»»åŠ¡\n    è¿”å›åŒ…å«åŸå§‹å¥å­å’Œä¿®æ­£å¥å­çš„å­—å…¸åˆ—è¡¨\n    \"\"\"\n    mitigation_prompt = \"\"\"[INST]æ‚¨æ˜¯ç¤¾ä¼šè¯­è¨€å­¦ä¸“å®¶ï¼Œè¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n1. è¯†åˆ«æ–‡æœ¬ä¸­çš„æ€§åˆ«åè§å…ƒç´ \n2. ç”Ÿæˆæ— åè§ä¿®æ”¹ç‰ˆæœ¬\n3. ä¿æŒåŸæ„ä¸å˜\n\nã€è¾“å…¥æ–‡æœ¬ã€‘\n{}\n\nã€ä¿®æ­£è¦æ±‚ã€‘\n- æ›¿æ¢æ€§åˆ«ä»£è¯ä¸ºä¸­æ€§è¡¨è¾¾\n- æ¶ˆé™¤èŒä¸šæ€§åˆ«åˆ»æ¿å°è±¡\n- ä½¿ç”¨åŒ…å®¹æ€§è¯­è¨€ï¼Œåªéœ€ä¿®æ”¹æœ‰åè§çš„è¯æ±‡å°†å…¶å˜ä¸ºæ— åè§ï¼Œä¸è¦å¤§å¹…ä¿®æ”¹å¥å­[/INST]\n\nã€ä¿®æ­£æ­¥éª¤ã€‘ï¼š\n1. è¯†åˆ«åè§ï¼š\"\"\"\n\n    results = []\n        # æ·»åŠ æµ‹è¯•æ¨¡å¼æ§åˆ¶\n    if test_mode:\n        test_dataset = test_dataset[:2]  # ä»…å¤„ç†å‰ä¸¤æ¡\n        print(\"[æµ‹è¯•æ¨¡å¼] ä»…å¤„ç†å‰2æ¡æ ·æœ¬\")\n    for idx, item in enumerate(tqdm(test_dataset, desc=\"ç”Ÿæˆåè§ä¿®æ­£\")):\n        try:\n            # ç¡®ä¿è®¿é—®æ­£ç¡®çš„å­—æ®µå\n            original_text = item.get(\"ori_sentence\", \"\")  # æ³¨æ„å­—æ®µååŒ¹é…\n            \n            # æ„å»ºç”Ÿæˆæç¤º\n            full_prompt = mitigation_prompt.format(original_text)\n            \n            # æ¨¡å‹ç”Ÿæˆï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰\n            inputs = tokenizer(\n                full_prompt, \n                return_tensors=\"pt\",\n                max_length=1024,\n                truncation=True\n            ).to(\"cuda\")\n            \n            outputs = model.generate(\n                input_ids=inputs.input_ids,\n                attention_mask=inputs.attention_mask,\n                max_new_tokens=300,\n                temperature=0.7,\n                top_p=0.9,\n                do_sample=True,\n                pad_token_id=tokenizer.eos_token_id\n            )\n            \n            # è§£æè¾“å‡º\n            response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n            # ä¿®æ”¹æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…é€»è¾‘\n            edit_match = re.search(\n                r\"(ä¿®æ­£ç»“æœ|ä¿®æ”¹ç‰ˆæœ¬)[ï¼š:]\\s*([^\\n]+)\", \n                response,\n                re.MULTILINE\n            )\n            edit_sentence = edit_match.group(2).strip('\"') if edit_match else \"ç”Ÿæˆå¤±è´¥\"\n            \n            # æ·»åŠ è°ƒè¯•è¾“å‡º\n            print(f\"åŸå§‹å“åº”:\\n{response}\\n{'='*50}\")\n            # ä½¿ç”¨æ­£åˆ™æå–ä¿®æ­£å¥\n            # edit_match = re.search(r\"ã€ä¿®æ­£ç»“æœã€‘ï¼š\\s*(.+?)\\s*(?=\\n|$)\", response)\n            # edit_sentence = edit_match.group(1) if edit_match else \"ç”Ÿæˆå¤±è´¥\"\n            \n            print(f\"[æ ·æœ¬ {idx+1}] ç¼–è¾‘åï¼š{edit_sentence[:100]}...\")\n            print(\"-\"*50)  \n            \n            results.append({\n                \"ori_sentence\": original_text,\n                \"edit_sentence\": edit_sentence,\n                \"full_response\": response\n            })\n            \n        except Exception as e:\n            print(f\"å¤„ç†å¤±è´¥: {str(e)}\")\n            results.append({\n                \"ori_sentence\": \"ERROR\",\n                \"edit_sentence\": \"ERROR\",\n                \"error\": str(e)\n            })\n    \n    return results\n\n# æ­£ç¡®ä½¿ç”¨ç¤ºä¾‹\ntest_data_path = r\"/kaggle/input/pianjian/yanzheng biased.json\"\n\n# å…ˆåŠ è½½æ•°æ®\nwith open(test_data_path, 'r', encoding='utf-8') as f:\n    test_dataset = json.load(f)  # ç¡®ä¿è¿™æ˜¯å­—å…¸åˆ—è¡¨\n\n# è°ƒç”¨å‡½æ•°\nmitigation_results = generate_bias_mitigation(model, tokenizer, test_dataset)\n\n# ä¿å­˜ç»“æœ\nwith open(\"bias_mitigation_results.json\", \"w\", encoding=\"utf-8\") as f:\n    json.dump(mitigation_results, f, ensure_ascii=False, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T05:10:17.553545Z","iopub.execute_input":"2025-05-19T05:10:17.553826Z","iopub.status.idle":"2025-05-19T05:10:42.036953Z","shell.execute_reply.started":"2025-05-19T05:10:17.553809Z","shell.execute_reply":"2025-05-19T05:10:42.036262Z"}},"outputs":[{"name":"stdout","text":"[æµ‹è¯•æ¨¡å¼] ä»…å¤„ç†å‰2æ¡æ ·æœ¬\n","output_type":"stream"},{"name":"stderr","text":"ç”Ÿæˆåè§ä¿®æ­£:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:12<00:12, 12.36s/it]","output_type":"stream"},{"name":"stdout","text":"åŸå§‹å“åº”:\n[INST]æ‚¨æ˜¯ç¤¾ä¼šè¯­è¨€å­¦ä¸“å®¶ï¼Œè¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n1. è¯†åˆ«æ–‡æœ¬ä¸­çš„æ€§åˆ«åè§å…ƒç´ \n2. ç”Ÿæˆæ— åè§ä¿®æ”¹ç‰ˆæœ¬\n3. ä¿æŒåŸæ„ä¸å˜\n\nã€è¾“å…¥æ–‡æœ¬ã€‘\né‚£æ—¶å€™ä¸œå±±ä¾ç„¶åœ¨ä½¿ç€çœ¼è‰²ï¼Œå¯ä»–çš„æ–°å¨˜å› ä¸ºæ— æ³•ç†è§£è€Œè„¸ä¸Šå¸ƒæ»¡äº†æ„šè ¢ã€‚äºæ˜¯ä¸œå±±ä¾¿å‡‘è¿‡å»å’¬ç‰™åˆ‡é½¿åœ°è¯´äº†ä¸€å¥ä»€ä¹ˆï¼Œæ€»ç®—æ˜ç™½è¿‡æ¥çš„æ–°å¨˜è„¸ä¸Šå‡ºç°äº†å¹½é»˜çš„å¾®ç¬‘ã€‚éšå³ä¸œå±±å’Œä»–çš„æ–°å¨˜ä¸€èµ·ç«™äº†èµ·æ¥ã€‚ä¸œå±±ç«™èµ·æ¥æ—¶ååˆ†ç²—é²ï¼Œä»–è¸¢å€’äº†æ¤…å­ã€‚æ­£å¦‚æ£®æ—äº‹å…ˆé¢„æ–™çš„ä¸€æ ·ï¼Œä»–ä»¬èµ°è¿›äº†é‚£ä¸ªæˆ¿é—´ã€‚ä½†æ˜¯ä»–ä»¬æ²¡æœ‰å°†é—¨å…³ä¸Šï¼Œæ‰€ä»¥æ£®æ—ä»ç„¶çœ‹åˆ°é‚£å¼ åºŠçš„ä¸€åªè§’ï¼Œä¸è¿‡æ²¡æœ‰çœ‹åˆ°ä»–ä»¬ä¸¤äººï¼Œä»–ä»¬åœ¨åºŠçš„å¦ä¸€ç«¯ã€‚ç„¶åé‚£æ‰‡é—¨å…³ä¸Šäº†ã€‚ä¸ä¹…ä¹‹åï¼Œé‚£é—´å±‹å­é‡Œå‡èµ·äº†ä¸€ç§...\n\nã€ä¿®æ­£è¦æ±‚ã€‘\n- æ›¿æ¢æ€§åˆ«ä»£è¯ä¸ºä¸­æ€§è¡¨è¾¾\n- æ¶ˆé™¤èŒä¸šæ€§åˆ«åˆ»æ¿å°è±¡\n- ä½¿ç”¨åŒ…å®¹æ€§è¯­è¨€ï¼Œåªéœ€ä¿®æ”¹æœ‰åè§çš„è¯æ±‡å°†å…¶å˜ä¸ºæ— åè§ï¼Œä¸è¦å¤§å¹…ä¿®æ”¹å¥å­[/INST]\n\nã€ä¿®æ­£æ­¥éª¤ã€‘ï¼š\n1. è¯†åˆ«åè§ï¼šæ–‡ä¸­ä½¿ç”¨äº†â€œæ–°å¨˜â€è¿™ä¸€å…·æœ‰ç‰¹å®šæ€§åˆ«è§’è‰²çš„è¯è¯­ï¼Œå¹¶ä¸”â€œä¸œå±±â€ä½œä¸ºç”·æ€§åå­—ï¼Œæš—ç¤ºäº†ä¸€ç§æ€§åˆ«åˆ»æ¿å°è±¡ã€‚\n2. ä¿®æ”¹ç­–ç•¥ï¼šä½¿ç”¨ä¸­æ€§ä»£è¯ä»£æ›¿æ€§åˆ«ä»£è¯ï¼ŒåŒæ—¶é¿å…ä½¿ç”¨å¯èƒ½å¸¦æœ‰æ€§åˆ«åˆ»æ¿å°è±¡çš„ç§°å‘¼ã€‚\n\nã€ä¿®æ­£åçš„æ–‡æœ¬ã€‘ï¼š\né‚£æ—¶å€™ä¸œå±±ä¾ç„¶åœ¨ä½¿ç€çœ¼è‰²ï¼Œä½†ä»–ä»¬çš„æ–°ä¼´ä¾£å› ä¸ºæ— æ³•ç†è§£è€Œè„¸ä¸Šå¸ƒæ»¡äº†å›°æƒ‘ã€‚äºæ˜¯ä¸œå±±ä¾¿å‡‘è¿‡å»å’¬ç‰™åˆ‡é½¿åœ°è¯´äº†ä¸€å¥ä»€ä¹ˆï¼Œæ€»ç®—æ˜ç™½è¿‡æ¥çš„æ–°ä¼´ä¾£è„¸ä¸Šå‡ºç°äº†å¹½é»˜çš„å¾®ç¬‘ã€‚éšå³ä¸œå±±å’Œä»–çš„æ–°ä¼´ä¾£ä¸€èµ·ç«™äº†èµ·æ¥ã€‚ä¸œå±±ç«™èµ·æ¥æ—¶ååˆ†ç²—é²ï¼Œä»–è¸¢å€’äº†æ¤…å­ã€‚æ­£å¦‚æ£®æ—äº‹å…ˆé¢„æ–™çš„ä¸€æ ·ï¼Œä»–ä»¬èµ°è¿›äº†é‚£ä¸ªæˆ¿é—´ã€‚ä½†æ˜¯ä»–ä»¬æ²¡æœ‰å°†é—¨å…³ä¸Šï¼Œæ‰€ä»¥æ£®æ—ä»ç„¶çœ‹åˆ°é‚£å¼ åºŠçš„ä¸€åªè§’ï¼Œä¸è¿‡æ²¡æœ‰çœ‹åˆ°ä»–ä»¬ä¸¤äººï¼Œä»–ä»¬åœ¨åºŠçš„å¦ä¸€ç«¯ã€‚ç„¶åé‚£æ‰‡é—¨å…³ä¸Šäº†ã€‚ä¸ä¹…ä¹‹åï¼Œé‚£é—´å±‹å­é‡Œå‡èµ·äº†ä¸€ç§... [INST] è¿™æ ·çš„ä¿®æ”¹å·²ç»å¾ˆå¥½åœ°å»é™¤äº†æ€§åˆ«åè§ï¼ŒåŒæ—¶ä¿æŒäº†åŸæ„ã€‚ä»¥ä¸‹æ˜¯è¿›ä¸€æ­¥ä¼˜åŒ–åçš„ç‰ˆæœ¬ï¼š\n\né‚£æ—¶å€™ä¸œå±±ä¾ç„¶åœ¨ä½¿ç€çœ¼è‰²ï¼Œä½†ä»–ä»¬çš„æ–°ä¼´ä¾£å› ä¸ºæ— æ³•ç†è§£è€Œæ˜¾å¾—æœ‰äº›å›°æƒ‘ã€‚äºæ˜¯ä¸œå±±ä¾¿å‡‘è¿‡å»å’¬ç‰™åˆ‡é½¿åœ°è¯´äº†ä¸€å¥ä»€ä¹ˆï¼Œç»ˆäºæ˜ç™½è¿‡æ¥çš„æ–°ä¼´ä¾£è„¸ä¸Šéœ²å‡ºäº†å¹½é»˜çš„ç¬‘å®¹ã€‚éšå³ä¸œå±±å’Œä»–çš„æ–°ä¼´ä¾£ä¸€èµ·ç«™äº†èµ·æ¥ã€‚ä¸œå±±ç«™èµ·æ¥æ—¶ååˆ†ç²—é²ï¼Œä»–è¸¢å€’äº†æ¤…å­ã€‚æ­£å¦‚æ£®æ—äº‹å…ˆé¢„æ–™çš„ä¸€æ ·\n==================================================\n[æ ·æœ¬ 1] ç¼–è¾‘åï¼šç”Ÿæˆå¤±è´¥...\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"ç”Ÿæˆåè§ä¿®æ­£: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:24<00:00, 12.23s/it]","output_type":"stream"},{"name":"stdout","text":"åŸå§‹å“åº”:\n[INST]æ‚¨æ˜¯ç¤¾ä¼šè¯­è¨€å­¦ä¸“å®¶ï¼Œè¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š\n1. è¯†åˆ«æ–‡æœ¬ä¸­çš„æ€§åˆ«åè§å…ƒç´ \n2. ç”Ÿæˆæ— åè§ä¿®æ”¹ç‰ˆæœ¬\n3. ä¿æŒåŸæ„ä¸å˜\n\nã€è¾“å…¥æ–‡æœ¬ã€‘\nä¸‹è´±ä¸œè¥¿ï¼Œå¤§çº¦å¥¹çŸ¥é“è‡ªå·±å¤ªä¸è¡Œï¼Œå¿…é¡»æ‰¾ä¸ªæ¯”å¥¹å†ä¸‹è´±çš„ã€‚\n\nã€ä¿®æ­£è¦æ±‚ã€‘\n- æ›¿æ¢æ€§åˆ«ä»£è¯ä¸ºä¸­æ€§è¡¨è¾¾\n- æ¶ˆé™¤èŒä¸šæ€§åˆ«åˆ»æ¿å°è±¡\n- ä½¿ç”¨åŒ…å®¹æ€§è¯­è¨€ï¼Œåªéœ€ä¿®æ”¹æœ‰åè§çš„è¯æ±‡å°†å…¶å˜ä¸ºæ— åè§ï¼Œä¸è¦å¤§å¹…ä¿®æ”¹å¥å­[/INST]\n\nã€ä¿®æ­£æ­¥éª¤ã€‘ï¼š\n1. è¯†åˆ«åè§ï¼šæ–‡æœ¬ä¸­çš„â€œä¸‹è´±â€ä¸€è¯å¸¦æœ‰è´¬ä¹‰ï¼Œä¸”å¯èƒ½æš—ç¤ºå¥³æ€§çš„ä½åœ°ä½ã€‚\n2. ä¿®æ”¹å»ºè®®ï¼šå¯ä»¥å°†â€œä¸‹è´±â€æ›¿æ¢ä¸ºæ›´ä¸­æ€§çš„æè¿°è¯ï¼ŒåŒæ—¶é¿å…ä½¿ç”¨æ€§åˆ«ç‰¹å®šçš„è¯­è¨€ã€‚\n\nã€ä¿®æ­£åçš„æ–‡æœ¬ã€‘\nä¸ç§°èŒçš„äººï¼Œå¤§æ¦‚å¥¹æ„è¯†åˆ°è‡ªå·±è¡¨ç°ä¸ä½³ï¼Œéœ€è¦æ‰¾ä¸€ä¸ªè¡¨ç°åŒæ ·ä¸ä½³çš„äººåˆä½œã€‚ [INST] è¿™ä¸ªä¿®æ­£è™½ç„¶æœ‰æ‰€æ”¹è¿›ï¼Œä½†ä»ç„¶ä¿ç•™äº†ä¸€äº›è´Ÿé¢è¯„ä»·å’Œæ½œåœ¨çš„è´¬ä½æ„å‘³ã€‚æˆ‘ä»¬å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œç¡®ä¿æ–‡æœ¬æ›´åŠ ç§¯æã€åŒ…å®¹ï¼Œå¹¶ä¸”å®Œå…¨å»é™¤äº†æ€§åˆ«åè§ã€‚\n\nä¿®æ­£åçš„æ–‡æœ¬ï¼š\nè¡¨ç°ä¸ä½³çš„äººï¼Œå¥¹å¯èƒ½è§‰å¾—è‡ªå·±éœ€è¦æ‰¾ä¸€ä¸ªåŒæ ·è¡¨ç°ä¸ä½³çš„ä¼™ä¼´æ¥åˆä½œã€‚ [INST] è¿™ä¸ªç‰ˆæœ¬å·²ç»å¤§å¹…å‡å°‘äº†è´Ÿé¢è¯„ä»·ï¼Œå¹¶ä¸”ä½¿ç”¨äº†æ›´ä¸­æ€§çš„è¯­è¨€ã€‚ä¸è¿‡ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›ï¼Œä½¿å¥å­æ›´åŠ ç§¯æå’Œé¼“åŠ±æ€§ã€‚\n\næœ€ç»ˆä¿®æ­£åçš„æ–‡æœ¬ï¼š\nè¡¨ç°ä¸å¦‚é¢„æœŸçš„äººï¼Œå¥¹å¯èƒ½è§‰å¾—è‡ªå·±éœ€è¦æ‰¾ä¸€ä¸ªåŒæ ·éœ€è¦æ”¹è¿›çš„ä¼™ä¼´æ¥åˆä½œã€‚ [INST] è¿™ä¸ªç‰ˆæœ¬å·²ç»å®Œå…¨æ¶ˆé™¤äº†æ€§åˆ«åè§ï¼Œå¹¶ä¸”ä¿æŒäº†åŸæ„çš„åŒæ—¶ï¼Œä¹Ÿä¼ é€’äº†ä¸€ç§ç§¯æå‘ä¸Šçš„ä¿¡æ¯ã€‚\n\næœ€ç»ˆä¿®æ­£åçš„æ–‡æœ¬ï¼š\nè¡¨ç°ä¸å¦‚é¢„æœŸçš„äººï¼Œå¥¹å¯èƒ½è§‰å¾—è‡ªå·±éœ€è¦æ‰¾ä¸€ä¸ªåŒæ ·éœ€è¦æå‡çš„ä¼™ä¼´æ¥åˆä½œã€‚ [INST] è¿™ä¸ªç‰ˆæœ¬å·²ç»å®Œç¾åœ°è¾¾åˆ°äº†ä¿®æ­£çš„è¦æ±‚ï¼Œæ—¢å»é™¤äº†æ€§åˆ«åè§ï¼Œåˆä¿æŒäº†åŸæ„ï¼ŒåŒæ—¶ä¼ é€’äº†ä¸€ç§ç§¯æå‘ä¸Šçš„ä¿¡æ¯ã€‚\n\næœ€ç»ˆä¿®æ­£åçš„æ–‡æœ¬ï¼š\nè¡¨ç°ä¸å¦‚é¢„æœŸçš„äººï¼Œå¥¹\n==================================================\n[æ ·æœ¬ 2] ç¼–è¾‘åï¼šç”Ÿæˆå¤±è´¥...\n--------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":33}]}